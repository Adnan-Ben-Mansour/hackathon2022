# Interpretability Hackathon - 11th-13th November 2022 : An intuitive logic for understanding autoregressive language models
_Adnan Ben Mansour, Gaia Carenini, Alexandre Duplessis_

### Description
We took some code from [ROME](https://github.com/kmeng01/rome) in order to do interpretability on natural language with GPT2-XL and GPT2-medium. In this notebook we tried to understand the intuitive logic behind logical operators like "and", "or", "but", etc... inside an auto-regressive language models. This work can be found in `/notebooks/final.ipynb`. 

In another notebook we also tried to investigate model editing effects on our interpretation. We cloned [ROME](https://github.com/kmeng01/rome) and created a notebook on which we ran several editing on adjectives and logical operators. This notebook, saved as `/notebooks/editing.ipynb`, has been modified a lot during our hackathon and might be incomplete regarding our experiments. 

### Informations
We ran our experiments on a NVIDIA RTX 3050 with 6GB of memory. 
